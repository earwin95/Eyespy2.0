// On importe les fonsctionnalites de react (useRef, useEffect, useState)
// On importe react-webcam pour acceder √† la webcam, cocco-ssd qui est un mod√®le d'IA 
// qui d√©tecte les objets, et tensorflow/tfjs qui est la biblioth√®que de tensorflow 
// pour le javascript afin de faire fonctionner le mod√®le d'IA

import React, { useRef, useEffect, useState } from 'react';
import Webcam from 'react-webcam';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import '@tensorflow/tfjs';


// On cr√©e la fonction ObjectDetection qui va g√©rer la d√©tection d'objets  


const ObjectDetection = () => {

// On cr√©e les variables
// webcamRef une ref√©rence pour acceder au flux video de la webcam
// canvasRef une ref√©rence pour dessiner les carr√©s de d√©tection 
// model pour stocker le mod√®le d'IA (coco-ssd)
// detections pour stocker les objets d√©tect√©s par le mod√®le d'IA

  const webcamRef = useRef(null);
  const canvasRef = useRef(null);
  const [model, setModel] = useState(null);
  const [detections, setDetections] = useState([]);

  // on utilise useEffect pour charger le mod√®le d'IA coco-ssd une seule fois 
  // On telecharge cooco-ssd et on le set dans la variable model 
  

  useEffect(() => {
    const loadModel = async () => {
      const loadedModel = await cocoSsd.load();
      setModel(loadedModel);
    };
    loadModel();
  }, []);

  // on cr√©e une fonction drawBoxes qui va dessiner les carr√©s de d√©tection sur les objets d√©tect√©s :
  // on cree une variable ctx qui est le contexte de dessin du canvas en utilisant
  //  canvasref.current.getContext('2d') pour acceder au contexte de dessin du canvas
// on met a 0 les attributs du canvas pour le redessiner

  const drawBoxes = (predictions) => {
    const ctx = canvasRef.current.getContext('2d');
    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);

    // on utilise une boucle forEach pour parcourir un tableau predictions 
    // qui contient les objets d√©tect√©s par le mod√®le d'IA coco-ssd
    // on cree une variable prediction.bbox qui contient les coordonn√©es et gandeur 
    // de l'objet d√©tect√© dans un tableau
    // on utilise ctx.strokeRect pour dessiner un rectangle autour de l'objet d√©tect√©
    // on utilise ctx.fillText pour afficher le nom et le score 

    predictions.forEach(prediction => {
      const [x, y, width, height] = prediction.bbox;
      ctx.strokeStyle = '#00FF00';
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, width, height);
      ctx.font = '16px Arial';
      ctx.fillStyle = '#00FF00';
      ctx.fillText(
        `${prediction.class} (${Math.round(prediction.score * 100)}%)`,
        x,
        y > 10 ? y - 5 : 10
      );
    });
  };

  // on utilise useEffect pour mettre √† jour les d√©tections toutes les 500ms

  // on utilise une fonction setInterval pour appeler la fonction detect du mod√®le d'IA coco-ssd 
  // et verifier si le modele est charg√© et si la webcam est pr√™te grace 
  // √† webcamRef.current.video.readyState === 4
  // on cree une variable predictions qui contient les objets d√©tect√©s par coco-ssd
  // on incremente predictions dans la variable detections
  // on appelle la fonction drawBoxes pour dessiner les carr√©s de d√©tection sur le canvas
  //on clear la fonction interval pour remettre √† z√©ro le setInterval une fois le retturn effectu√©
  // on utilise le tableau de d√©pendances [model] pour que l'effet ne s'ex√©cute 
  // qu'une seule fois lorsque le mod√®le est charg√©

  useEffect(() => {
    if (model) {
      const interval = setInterval(async () => {
        if (
          webcamRef.current &&
          webcamRef.current.video.readyState === 4
        ) {
          const predictions = await model.detect(webcamRef.current.video);
          setDetections(predictions);
          drawBoxes(predictions);
        }
      }, 500);
      return () => clearInterval(interval);
    }
  }, [model]);

  // on cr√©e une fonction capture 
  // on cree une variabble screenshot en utilisant webcamRef.current.getScreenshot() 
  // pour prendre une capture d'√©cran de la webcam
  // on cree une variable now qui contient la date et l'heure actuelle
  // on cree une variable predictionNames qui contient les noms des objets d√©tect√©s 
  

  const capture = () => {
    const screenshot = webcamRef.current.getScreenshot();
    const now = new Date().toLocaleString();
    const predictionNames = detections.map(d => d.class).join(', ');

// on cree une variable captureData qui contient la date, les objets d√©tect√©s et l'image
    const captureData = {
      date: now,
      objects: predictionNames,
      image: screenshot,
    };

    // on cree une variable old capture pour sauvegarder les capuresData dans le local storage
    // on utilise JSON.parse pour convertir les donn√©es en format JSON en un tableau d'objets javascript 
    // et localStorage.getItem pour recuperer les donn√©es du local storage
    // on utilise push pour ajouter la nouvelle capture √† l'ancien tableau de captures
    // on utilise JSON.stringify pour convertir le tableau d'objets javascript en une cha√Æne de caract√®res JSON 
    // et localStorage.setItem pour sauvegarder les donn√©es dans le local storage

    
    const oldCaptures = JSON.parse(localStorage.getItem('captures')) || [];
    oldCaptures.push(captureData);
    localStorage.setItem('captures', JSON.stringify(oldCaptures));
    alert('Capture sauvegard√©e !');
  };

  return (
    <div className="flex flex-col items-center p-4 space-y-4">
      <div className="relative">
        <Webcam
          ref={webcamRef}
          audio={false}
          screenshotFormat="image/jpeg"
          width={640}
          height={480}
          className="rounded shadow"
          videoConstraints={{ facingMode: 'user' }}
        />
        <canvas
          ref={canvasRef}
          width={640}
          height={480}
          className="absolute top-0 left-0"
        />
      </div>

      <button
        onClick={capture}
        className="bg-green-600 text-white px-4 py-2 rounded shadow hover:bg-green-700"
      >
        üì∏ Capturer et sauvegarder
      </button>
    </div>
  );
};

export default ObjectDetection;